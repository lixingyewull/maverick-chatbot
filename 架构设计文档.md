## 总体架构
- 前端（`frontend/`，Vite）
  - 采集麦克风音频（`wav-recorder.js`），通过 WebSocket 与后端实时交互，展示文本与音频播放。
- 后端（Java Spring Boot）
  - WebSocket 接入：`VoiceWebSocketConfig`、`VoiceWebSocketHandler`、`WebSocketContainerConfig`
  - AI 编排：`ai/` 下的 ASR、RAG、TTS 模块与编排器
  - 角色/配置与 REST：`RoleController`、`JsonUtil`、`config/HttpClientConfig`
- 模型与外部服务
  - TTS/ASR 推理：`docker/sherpa-onnx`（Python 微服务）、`models/sherpa/`（ONNX 模型）
  - RAG 存储：`chroma-data/`（Chroma 向量库）
- 资源与提示词
  - 角色配置：`src/main/resources/roles/roles.yaml`
  - 系统提示词：`system-prompt.txt`、`transfer-system-prompt.txt`
  - 语料/样例音频：`resources/docs/`、`resources/voice/`

### 运行时数据流（语音对话链路）
1. 前端打开 WebSocket，持续发送音频分片与控制消息。
2. 后端 `VoiceWebSocketHandler` 接收音频，调用 ASR 输出“中间/最终文本”。
3. `ConversationOrchestrator` 触发 RAG：从 Chroma 召回文档片段，结合角色与系统提示词整合为回复。
4. 将回复文本送入 TTS 微服务生成语音流，后端以流式音频/事件消息回传前端。
5. 前端播放语音、渲染文本，进入下一轮。

## 模块设计与规格

### 1) WebSocket 接入层
- 职责
  - 维护会话生命周期、鉴权（若启用）、音频/文本的双向流式通讯
  - 消息编解码、限流与错误处理
- 关键类
  - `web/VoiceWebSocketConfig`：WebSocket 端点配置
  - `web/VoiceWebSocketHandler`：消息处理、调用 ASR/RAG/TTS
  - `web/WebSocketContainerConfig`：容器层参数（线程、缓冲配置）
- 主要输入/输出
  - 输入：音频分片（建议 PCM16/WAV Base64 或二进制）、控制/会话消息（JSON）
  - 输出：ASR 中间/最终文本、RAG 回复文本、TTS 音频分片/完成事件
- 配置
  - WebSocket 路径、消息大小、并发连接数、超时
- 错误
  - 非法消息格式、音频采样不匹配、下游模块超时 → 以错误事件 JSON 返回

### 2) ASR 模块（`ai/asr`）
- 职责
  - 将音频分片转为文本，支持增量/最终结果
- 关键类（根据目录推断）
  - `SpeechToTextService`（在 `target/classes` 可见）：ASR 服务接口
  - `impl/...`：具体实现类（可能调用 Sherpa-ONNX 微服务或本地 JNI）
- 接口（建议）
  - `startSession(sessionId, sampleRate, language)`
  - `pushAudio(sessionId, pcmChunk)`
  - `flush(sessionId) -> finalText`
- 依赖
  - Docker 中的 `sherpa-onnx/server.py` 或本地进程
- 配置
  - 采样率、音频格式、分段时长、ASR 语言与解码参数

### 3) RAG 模块（`ai/rag`）
- 职责
  - 基于对话上下文与角色提示，从 Chroma 向量库检索相关片段，编排最终回复
- 关键类
  - `ConversationOrchestrator`：对话编排核心（ASR 文本→检索→生成→TTS）
  - `RagSearchService`：向量检索、重排序
  - `RagConfig`：RAG 参数（topK、阈值、Prompt 模板等）
- 输入/输出
  - 输入：用户文本、会话上下文、角色设定
  - 输出：回复文本、可选结构化引用（命中文档片段）
- 数据
  - `chroma-data/`：索引、sqlite3
  - `resources/docs/`：原始语料，`tools/RagIngestRunner` 用于入库
- 错误
  - 检索为空（返回 fallback 策略）、召回超时、索引损坏

### 4) 角色与提示词（`ai/roles` + `resources/roles/roles.yaml`）
- 职责
  - 管理角色清单、默认系统 Prompt、语气/风格、说话人（与 TTS 音色映射）
- 关键点
  - `RoleController` 提供角色相关 REST 能力（列举、切换、查询详情）
  - `system-prompt.txt`、`transfer-system-prompt.txt` 作为系统级提示词模板
- 配置/数据
  - `roles.yaml`：定义角色 id、名称、persona、约束、关联音色

### 5) TTS 模块（`ai/tts`）
- 职责
  - 将回复文本合成为语音，支持流式分片下发
- 关键类
  - `TtsService`：TTS 服务接口
  - `tts/impl/...`：具体实现（通常 HTTP/GRPC 调用 `docker/sherpa-onnx/server.py`）
- 接口（建议）
  - `synthesizeStream(sessionId, text, voice, lang) -> Iterable<audioChunk>`
- 依赖与模型
  - `models/sherpa/` 下 ONNX 模型、`tokens.txt`
- 配置
  - 语速、语调、音量、音色映射、最大时长、并发度

### 6) 工具与调试（`tools/`）
- `RagIngestRunner`：离线将 `resources/docs/` 语料嵌入并写入 `chroma-data/`
- `TtsDebugger`：本地单点合成测试
- `uploadAndStatus.py`：文件上传与状态查询（用于批量导入或调试）

### 7) 公共与基础设施
- `AiCodeHelperService`、`AiCodeHelperServiceFactory`：AI 能力工厂/门面（贯通 ASR/RAG/TTS）
- `config/HttpClientConfig`：HTTP/WebClient/RestTemplate 统一配置（连接池、超时、重试）
- `web/JsonUtil`、`web/dto/*`：通用 JSON/DTO
